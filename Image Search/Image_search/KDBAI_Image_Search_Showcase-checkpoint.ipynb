{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "869e1e5c-2655-41c8-89b7-86012e886c7d",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698f2167-faac-4177-ba16-9515dfe2af74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "### ignore tensorflow warnings\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "#force tensorflow to use CPU only\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dae5c6-e11b-4784-b701-8eababa609cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download data\n",
    "from zipfile import ZipFile\n",
    "#embeddings\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "import tensorflow as tf\n",
    "from huggingface_hub import from_pretrained_keras\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#timing\n",
    "from tdqm.auto import tdqm\n",
    "#vector DB\n",
    "import kdbai_client as kdbai\n",
    "from getpass import getpass\n",
    "import time\n",
    "#plotting\n",
    "import umap.umap_ as umap\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98d749a-4436-412e-827a-79330dc97629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    print(df.shape)\n",
    "    return df.head()\n",
    "\n",
    "def plot_image(axis, source: str, label=None) -> None:\n",
    "    axis.imshow(plt.imread(source), cmap = 'gray')\n",
    "    axis.axis(\"off\")\n",
    "    title = (f\"{label}: \" if label else \"\") + source.split(\"/\")[-1]\n",
    "    axis.set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04049c35-55dd-4f9d-a17e-f8d0fcbca7f7",
   "metadata": {},
   "source": [
    "## 1. Load Image Data\n",
    "\n",
    "### Define list of paths to the extracted image files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cc4ae3-1397-4dd0-a370-929cabfdc97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_file_paths_from_folder(parent_dir: str) -> dict:\n",
    "    image_paths = {}\n",
    "    for sub_folder in os.listdir(parent_dir):\n",
    "        sub_dir = os.path.join(parent_dir, sub_folder)\n",
    "        image_paths[sub_folder] = [\n",
    "            os.path.join(sub_dir, file) for file in os.listdir(sub_dir)\n",
    "        ]\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab078b1-775d-465c-8d90-5f52bce915aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths_map = extract_file_paths_from_folder(\"COVID-images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873383aa-737c-478f-b817-837f8958a3ee",
   "metadata": {},
   "source": [
    "### Visualize Some of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c57eef5-375f-47ec-8640-3d3f73a57773",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_index = 14\n",
    "_, ax = plt.subplots(nrows = len(image_paths_map) // 2, ncols=2, figsize=(10,8))\n",
    "axes = ax.reshape(-1)\n",
    "for i, (_, image_paths) in enumerate(image_paths_map.items()):\n",
    "    for path in image_paths:\n",
    "        if path.endswith(f\"{image_index}.png\"):\n",
    "            break\n",
    "\n",
    "    plot_image(axes[i], path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851bbae7-d856-475d-bda8-a6ec0a8587b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = image_dataset_from_directory(\n",
    "    \"COVID-images\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    shuffle=False,\n",
    "    seed=1,\n",
    "    image_size=(299,299),\n",
    "    batch_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ffc3aa-38fd-45ca-83fa-f20038fc0be0",
   "metadata": {},
   "source": [
    "## 2. Create Image Vector Embeddings\n",
    "\n",
    "To create our image embeddings, we will use a neural network which we have pre-trained on the lung classifications. In this showcase, we will use the ResNet-50 nerual network architcture, a popular choice for general image classification.\n",
    "\n",
    "ResNet-50 was originally trained on the ImageNet dataset - although this dataset contains millions of images, including X-ray scans, we would like it to be a bit more custom suited working with our dataset and the classifications we assign to it. Therefore our model here was ,ade by taking ResNet50, pre-trained on ImageNet, and re-training it to classify X-ray scan images of lungs.\n",
    "\n",
    "We trained the model using roughly 70% of the Kaggle dataset, split equally among the 4 classifications. We then use the remaining 30% of data in this showcase for embedding as vectors and using to perform image search on.\n",
    "\n",
    "### Load Pre-Trained classification neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b90974-00ab-42f4-932f-ec6040e45fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('saved_model/lungs_model.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279f040f-7e6b-43da-af8a-8be73a7fa5b6",
   "metadata": {},
   "source": [
    "### Use embedding network to create image embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ef7b31-34e8-4e03-b41a-16727a769ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.empty([len(dataset), 2048])\n",
    "labels = np.empty([len(datset),4])\n",
    "for i, image in tqdm(enumerate(dataset), total=len(dataset)):\n",
    "    embeddings[i, :] = model.predict(image[0], verbose=0)\n",
    "    labels[i, :] = image[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5690ee7e-bb3e-4db9-bb22-fe0dc037d75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the disease types in order\n",
    "lung_types = sorted(image_paths_map.keys())\n",
    "#for each vector, save the disease type given by the index\n",
    "class_labels = [lung_types[label.argmax()] for label in labels]\n",
    "#get a single list of all paths\n",
    "all_paths = []\n",
    "for _, image_paths in image_paths_map.items():\n",
    "    all_paths += image_paths\n",
    "#sort the source files in alphanumeric order\n",
    "sorted_all_paths = sorted(all_paths)\n",
    "#define our DataFrame for insertion into KDB.AI\n",
    "embedded_df = pd.DataFrame(\n",
    "    {\n",
    "        \"source\": sorted_all_paths,\n",
    "        \"class\": class_labels,\n",
    "        \"embedding\": embeddings.tolist(),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8955ee1f-7513-4ee3-b711-9bce9bef04db",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_df(embedded_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b18346-2ed5-4d39-966d-9ebf0fad03cd",
   "metadata": {},
   "source": [
    "### Visualising the embeddings\n",
    "\n",
    "It is quite difficult to grasp the concept of a high dimensional vector embedding. One trick to help us try and see this is by using UMAP: a technique which reduces the number of dimensions to allow us to visualize the clusterings in 2D. This will allow to us to get an initial grasp of how well classifications have been separated within the embeddings, and also some potential misclassifications that may occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f35cd1e-bd8e-42cd-a308-563990353700",
   "metadata": {},
   "outputs": [],
   "source": [
    "_umap = umap.UMAP(n_neighbors=15, min_dist=0.0)\n",
    "umap_df = pd.DataFrame(_umap.fit_transform(embeddings), columns=[\"u0\", \"u1\"])\n",
    "show_df(umap_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64363a8d-18e7-4f3e-9be4-69392d0c7d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_colors = [\"blue\", \"red\", \"green\", \"purple\"]\n",
    "#Create figure for plotting\n",
    "plt.figure(figsize=(10, 8))\n",
    "#Scatter plot with 'u0' and 'u1' columns as x and y, color mapped by class labels\n",
    "for lung_type, color in zip(lung_types, class_colors):\n",
    "    indices_to_plot = [i for i, label in enumerate(class_labels) if label == tumor_type]\n",
    "    subset = umap_df.iloc[indices_to_plot]\n",
    "    plt.scatter(subset[\"u0\"], subset[\"u1\"], label=lung_type, color=color, alpha=0.5)\n",
    "\n",
    "plt.title(\"Embeddings Map For X-ray Lung Scan Images\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9995e122-633a-4510-8f06-50f0649df23e",
   "metadata": {},
   "source": [
    "## 3. Store Embeddings in KDB.AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b041b9-d0f3-4b6c-bbd1-55e4fcd89adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = kdbai.Session(endpoint=\"http://localhost:8082\")\n",
    "image_schema = {\n",
    "    \"columns\": [\n",
    "        {\"name\": \"source\", \"pytype\": \"str\"},\n",
    "        {\"name\": \"class\", \"pytpe\": \"str\"},\n",
    "        {\n",
    "            \"name\": \"embedding\",\n",
    "            \"vectorIndex\": {\"dims\":2048, \"metric\":\"IP\", \"type\": \"flat\"},\n",
    "        },\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab58f915-8015-442a-9f4c-327cc21fdd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    session.table(\"lungs\").drop()\n",
    "    time.sleep(5)\n",
    "except kdbai.KDBAIException:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37a17e3-08b4-4a99-8119-99f92bc04e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = session.create_table(\"lungs\", image_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f253e227-ac27-42b3-b390-3623c650b4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_df.memory_usage(deep=True).sum() / (1024**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec844022-68e9-4f39-99ad-f39a4466db78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Yield successive n-sized chunks from l\n",
    "def divide_chunks(l, n):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "#How many elements each list should have\n",
    "n = len(embedded_df) // 12\n",
    "#Now split the data \n",
    "embedded_df_split = list(divide_chunks(embedded_df, n))\n",
    "#and insert the now acceptably sized chunks\n",
    "for i in tqdm(range(len(embedded_df_split))):\n",
    "    table.insert(embedded_df_split[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8d3cf8-2120-45b8-9c26-f599ff4c5fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4beb00-263a-496d-adce-a6831629aaba",
   "metadata": {},
   "source": [
    "## 4. Query KDB.AI Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e76193-f18e-4f53-845e-3fb481c4bbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc640bf-f22f-4e6a-aa8e-ed737ced3a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.query(filter=[(\"like\", \"class\", \"*Lung*\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3006f5-f9db-4cbb-b716-e0a6b1c7d3dd",
   "metadata": {},
   "source": [
    "## 5. Search for similar images to a target image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afa9059-51b5-44bd-9cfd-5c9e345f8470",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a sample row\n",
    "row_index_1 = 140\n",
    "#Select the random row and the desired colimn's value\n",
    "row_1 = embedded_df.iloc[row_index_1]\n",
    "plot_image(plt.subplots()[-1], row_1[\"source\"], label=\"Query Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d315c2-32ae-4628-87c7-6b78a04f3c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_embedding_1 = row_1[\"embedding\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
